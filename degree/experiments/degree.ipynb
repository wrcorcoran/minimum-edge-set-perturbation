{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from dgl.data import CoraGraphDataset\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up DGL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "g = None\n",
    "in_feats = None\n",
    "h_feats = None\n",
    "num_classes = None\n",
    "cora_dataset = None\n",
    "features = None\n",
    "\n",
    "# reset_dataset() is used to reset the dataset (duh!) after changes\n",
    "def reset_dataset():\n",
    "    global g, in_feats, h_feats, num_classes, cora_dataset, features\n",
    "\n",
    "    cora_dataset = CoraGraphDataset()\n",
    "    g = cora_dataset[0]\n",
    "    features = g.ndata['feat']\n",
    "\n",
    "    in_feats = features.shape[1]\n",
    "    h_feats = 64\n",
    "    num_classes = cora_dataset.num_classes\n",
    "\n",
    "reset_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Saved Model + Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, g, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = dgl.nn.GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = dgl.nn.GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GraphConv(in=1433, out=64, normalization=both, activation=None)\n",
       "  (conv2): GraphConv(in=64, out=7, normalization=both, activation=None)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(g, in_feats, h_feats, num_classes)\n",
    "model.load_state_dict(torch.load(\"../model/cora_gt.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data, features)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    acc = (pred[data.ndata[\"test_mask\"]] == data.ndata[\"label\"][data.ndata[\"test_mask\"]]).sum().item() / data.ndata[\"test_mask\"].sum().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to calculate the change in accuracy\n",
    "def changed_acc(gt, cv):\n",
    "    print(\"\\n----\")\n",
    "    if gt != cv:\n",
    "        print(f'The accuracy has changed by {gt - cv:.4f}')\n",
    "    else:\n",
    "        print(\"The accuracy has not changed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.769"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = test(cora_dataset[0])\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "**Note:** The ground truth here is $0.769$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
